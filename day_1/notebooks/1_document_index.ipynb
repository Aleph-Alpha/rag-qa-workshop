{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA_TOKEN=os.getenv(\"AA_TOKEN\")\n",
    "NAMESPACE=os.getenv(\"AA_NAMESPACE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's have a look at the UI.  \n",
    "Visit: https://app.document-index.aleph-alpha.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating A Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intelligence_layer.connectors import (\n",
    "    CollectionPath,\n",
    "    DocumentIndexClient,\n",
    ")\n",
    "def create_collection(collection_name: str):\n",
    "    # TODO\n",
    "    #   - create DocumentIndexClient object\n",
    "    #   - create CollectionPath object\n",
    "    #   - use DocumentIndexClient to create a collection\n",
    "    pass\n",
    "\n",
    "CUSTOM_PREFIX = \"your-name\" # TODO: add your name here, so that your collection names don't collide with the others.\n",
    "\n",
    "COLLECTION_NAME=f\"{CUSTOM_PREFIX}-demo\"\n",
    "COLLECTION_NAME_DELETE=f\"{CUSTOM_PREFIX}-demo-collection-delete\"\n",
    "\n",
    "create_collection(COLLECTION_NAME)\n",
    "create_collection(COLLECTION_NAME_DELETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all the Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collections():\n",
    "    # TODO\n",
    "    #   - create DocumentIndexClient object\n",
    "    #   - use DocumentIndexClient to get the collections\n",
    "    #   - return the collections\n",
    "    collections = []\n",
    "    return collections\n",
    "collections = get_collections()\n",
    "collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete a Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _delete_collection(collection_name: str):\n",
    "    # TODO\n",
    "    #   - create DocumentIndexClient object\n",
    "    #   - create CollectionPath object\n",
    "    #   - use DocumentIndexClient object to delete the collection given by the CollectionPath\n",
    "    pass\n",
    "\n",
    "_delete_collection(COLLECTION_NAME_DELETE)\n",
    "# get collections to see if it was successfull\n",
    "get_collections()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Content of Document (PDF, TXT and DOCX) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parser import FileParser\n",
    "import os\n",
    "\n",
    "def get_file_content(path) -> tuple[str, str]:\n",
    "    \"\"\"Returns content and file name.\"\"\"\n",
    "    parser = FileParser()\n",
    "    file_content, file_name = parser.parse(path)\n",
    "    return file_content, file_name\n",
    "\n",
    "\n",
    "PATH_PDF = os.path.join(\"..\", \"..\", \"example_documents\", \"Der-Schattenmann.pdf\")\n",
    "PATH_TXT = os.path.join(\"..\", \"..\", \"example_documents\", \"Plyscraper.txt\")\n",
    "PATH_DOCX = os.path.join(\"..\", \"..\", \"example_documents\", \"Erfundene-Programmiersprache.docx\")\n",
    "\n",
    "\n",
    "file_content, file_name = get_file_content(PATH_DOCX)\n",
    "\n",
    "print(\"File name:\", file_name, \"\\n\", \"-\"*50)\n",
    "print(file_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from intelligence_layer.connectors import (\n",
    "    CollectionPath,\n",
    "    DocumentContents,\n",
    "    DocumentIndexClient,\n",
    "    DocumentPath,\n",
    ")\n",
    "from datetime import datetime\n",
    "\n",
    "def upload_document(file_path: str, collection_name: str):\n",
    "    # TODO\n",
    "    #   - create DocumentIndexClient object\n",
    "    #   - create CollectionPath object\n",
    "    #   - parse content of the file\n",
    "    #   - create DocumentPath object\n",
    "    #   - create DocumentContents object using the from_text class method\n",
    "    #   - add metadata to the DocumentContents object\n",
    "    #   - use DocumentIndexClient to add the document (DocumentPath, content)\n",
    "    pass\n",
    "\n",
    "upload_document(PATH_PDF, COLLECTION_NAME)\n",
    "upload_document(PATH_TXT, COLLECTION_NAME)\n",
    "upload_document(PATH_DOCX, COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all Documents within a Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intelligence_layer.connectors import (\n",
    "    CollectionPath,\n",
    "    DocumentIndexClient,\n",
    ")\n",
    "def get_documents(collection_name: str):\n",
    "    # TODO\n",
    "    #   - create DocumentIndexClient object\n",
    "    #   - create CollectionPath object\n",
    "    #   - get documents using the DocumentIndexClient \n",
    "    #   - return documents\n",
    "    documents = []\n",
    "    return documents\n",
    "\n",
    "documents = get_documents(COLLECTION_NAME)\n",
    "\n",
    "for document in documents:\n",
    "    print(document.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Single Document (and Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intelligence_layer.connectors import (\n",
    "    CollectionPath,\n",
    "    DocumentIndexClient,\n",
    "    DocumentPath\n",
    ")\n",
    "def get_document(collection_name: str, document_name: str):\n",
    "    # TODO\n",
    "    #   - create DocumentIndexClient object\n",
    "    #   - create CollectionPath object\n",
    "    #   - create DocumentPath object\n",
    "    #   - use DocumentIndexClient to get a single document given by DocumentPath\n",
    "    document = None\n",
    "    return document\n",
    "\n",
    "document_name_pdf = \"Der-Schattenmann.pdf\"\n",
    "document_name_txt = \"Plyscraper.txt\"\n",
    "document_name_docx = \"Erfundene-Programmiersprache.docx\"\n",
    "\n",
    "document = get_document(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    document_name=document_name_pdf\n",
    ")\n",
    "\n",
    "print(document.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intelligence_layer.connectors import (\n",
    "    CollectionPath,\n",
    "    DocumentIndexClient,\n",
    "    IndexConfiguration,\n",
    "    IndexPath,\n",
    ")\n",
    "\n",
    "def _create_index(index_name: str, chunk_size: int):\n",
    "    # TODO\n",
    "    #   - create DocumentIndexClient object\n",
    "    #   - create IndexPath object\n",
    "    #   - create IndexConfiguration object\n",
    "    #   - use DocumentIndexClient to create a index (IndexPath, IndexConfiguration)\n",
    "    return None\n",
    "\n",
    "INDEX_NAME = f\"{CUSTOM_PREFIX}demo-index\"\n",
    "chunk_size = 128\n",
    "_create_index(INDEX_NAME, chunk_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Index to Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _assign_index_to_collection(collection_name: str, index_name: str):\n",
    "    # TODO\n",
    "    #   - create DocumentIndexClient object\n",
    "    #   - create CollectionPath object\n",
    "    #   - use DocumentIndexClient to assign the index to the collection\n",
    "    return None\n",
    "\n",
    "_assign_index_to_collection(COLLECTION_NAME, INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_indexes(collection_name: str):\n",
    "    # TODO\n",
    "    #   - create DocumentIndexClient object\n",
    "    #   - create CollectionPath object\n",
    "    #   - use DocumentIndexClient to list the assined indexes\n",
    "    indexes = []\n",
    "    return indexes\n",
    "\n",
    "indexes = get_all_indexes(collection_name=COLLECTION_NAME)\n",
    "indexes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intelligence_layer.connectors import (\n",
    "    CollectionPath,\n",
    "    DocumentIndexClient,\n",
    "    DocumentIndexRetriever,\n",
    ")\n",
    "def similariy_search(collection_name:str, index_name: str, query: str):\n",
    "    # TODO\n",
    "    #   - create DocumentIndexClient object\n",
    "    #   - create DocumentIndexRetriever object\n",
    "    #   - use DocumentIndexRetriever to get relevant documents for given query\n",
    "    relevant_documents = []\n",
    "    return relevant_documents\n",
    "\n",
    "query = \"plyscraper\"\n",
    "relevant_documents = similariy_search(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    index_name=INDEX_NAME,\n",
    "    query=query\n",
    ")\n",
    "relevant_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Data for RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCEPTED_FILE_EXTENSTIONS = [\"txt\", \"docx\", \"pdf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = f\"{CUSTOM_PREFIX}-rag-collection\"\n",
    "index_name = f\"{CUSTOM_PREFIX}-rag-index\"\n",
    "chunk_size = 128\n",
    "file_directory_path = os.path.abspath(os.path.join(\"..\", \"..\", \"example_documents\"))\n",
    "\n",
    "# TODO create a collection\n",
    "for root, dirs, files in os.walk(file_directory_path):\n",
    "    for file in files:\n",
    "        file_extenstion = file[file.rfind(\".\")+1:]\n",
    "        if file_extenstion in ACCEPTED_FILE_EXTENSTIONS:\n",
    "            file_path = os.path.join(root,file)\n",
    "            # TODO upload document\n",
    "\n",
    "# TODO create index\n",
    "# TODO assign index to collection\n",
    "# TODO get documents (to check if it worked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload quad dataset\n",
    "\n",
    "1. Load the huggingface dataset located at `deepset/germanquad` and sample a subset (n=10).\n",
    "2. Create an index and assign it to the collection.\n",
    "3. Load the content of the `context` columns as documents into collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "collection_name = f\"{CUSTOM_PREFIX}-rag-collection\"\n",
    "index_name = f\"{CUSTOM_PREFIX}-rag-index\"\n",
    "\n",
    "HF_DATASET_NAME = \"deepset/germanquad\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
