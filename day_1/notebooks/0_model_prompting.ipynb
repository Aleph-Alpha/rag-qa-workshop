{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Connection\n",
    "Make sure to copy the `.env-template` to `.env` and fill in your Aleph Alpha API token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intelligence_layer.core import (\n",
    "    LuminousControlModel,\n",
    "    CompleteInput,\n",
    "    InMemoryTracer,\n",
    ")\n",
    "\n",
    "tracer = InMemoryTracer()\n",
    "\n",
    "model = LuminousControlModel(name=\"luminous-nextgen-7b-control-384k\")\n",
    "\n",
    "prompt = model.to_instruct_prompt(\n",
    "    instruction=\"Du bist ein Assistent, der Fragen beantwortet.\",\n",
    "    input=\"Wann wurde Köln gegründet?\",\n",
    ")\n",
    "complete_input = CompleteInput(prompt=prompt)\n",
    "response = model.complete(complete_input, tracer=tracer)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atman for Source Highlighting\n",
    "1. Run the instruction-input tuple below with the previously instantiated model.\n",
    "2. Create a `TextHighlight` task with the same model and run it on the same prompt and the generated output.\n",
    "3. Output the found highlights ordered by the score.\n",
    "4. Change the wording in `user_input` from \"spannend\" to \"langweilig\", rerun and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intelligence_layer.core import (\n",
    "    TextHighlight,\n",
    "    TextHighlightInput,\n",
    ")\n",
    "from aleph_alpha_client import PromptGranularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = (\n",
    "    \"Sie sind ein Assistent, der Filmkritiken klassifiziert. Sie müssen entscheiden, ob die Person den Film mochte oder nicht.\"\n",
    "    + ' Die Ausgabe sollte nur aus den Labels \"mögen\" oder \"nicht mögen\" bestehen.'\n",
    ")\n",
    "user_input = (\n",
    "    \"Nachricht: Ich habe gestern einen Film geschaut. Es ging um einen Agenten, der eine Mission erfüllen musste. Es war wirklich spannend.\"\n",
    "    + \" Zunächst musste der Agent eine Basis infiltrieren. Dort gab es einen Bösewicht. Blablabla. Lorem Ipsum dolor.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
